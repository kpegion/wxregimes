{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is the first step in reproducing the cluster analysis from Sara and David following Amini et al 2019\n",
    "https://doi.org/10.1007/s00382-018-4409-7\n",
    "\n",
    "This program:\n",
    "1. Reads in Z500 and U250 from ERA-Interim for Dec-Jan-Feb-Mar 1980/81 to 2014/15\n",
    "* Data are located in: \n",
    "`/shared/working/rean/era-interim/daily/data/yyyy/ei.oper.an.pl.regn128cm.yyyymmddhh`\n",
    "2. Subsets to the PNA region\n",
    "* Defined as: 150-300E; 20-80N\n",
    "3. Interpolates the data to a 126x64 Gaussian Grid\n",
    "4. Writes datasets out to a netcdf files containing both variables \n",
    "* Output file is located in: `/project/predictability/kpegion/wxregimes/era-interim/erai.z500_u250_pna_5dyrm_DJF.1980-2015.nc`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocZ(ds):\n",
    "\n",
    "    # Extract PNA region and 500hPa level\n",
    "    ds=ds.sel(isobaricInhPa=500,latitude=slice(80,20),longitude=slice(150,300))\n",
    "\n",
    "    # Create a new xarray dataset for z500\n",
    "    ds_tmp=xr.DataArray(ds['z'],\n",
    "                        coords={'lat':ds['latitude'].values,\n",
    "                                'lon': ds['longitude'].values},\n",
    "                            dims=['lat','lon'])        \n",
    "    ds_tmp=ds_tmp.to_dataset(name='z500')\n",
    "    \n",
    "    # Interpolate data to coarser grid\n",
    "    ds_new_grid=xr.open_dataset('tempgaussian.128x64.nc')\n",
    "    ds_new_grid=ds_new_grid.rename({'temp':'z500'}).sel(lat=slice(80,20),lon=slice(150,300))\n",
    "    ds=ds_tmp.interp_like(ds_new_grid)\n",
    "    \n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocU(ds):\n",
    "\n",
    "    # Extract PNA region and 250hPa level\n",
    "    ds=ds.sel(isobaricInhPa=250,latitude=slice(80,20),longitude=slice(150,300))\n",
    "\n",
    "    # Create a new xarray dataset for u250\n",
    "    ds_tmp=xr.DataArray(ds['u'],\n",
    "                    coords={'lat':ds['latitude'].values,\n",
    "                            'lon': ds['longitude'].values},\n",
    "                            dims=['lat','lon'])        \n",
    "    ds_tmp=ds_tmp.to_dataset(name='u250')\n",
    "\n",
    "    # Interpolate data to coarser grid\n",
    "    ds_new_grid=xr.open_dataset('tempgaussian.128x64.nc')\n",
    "    ds_new_grid=ds_new_grid.rename({'temp':'u250'}).sel(lat=slice(80,20),lon=slice(150,300))\n",
    "    ds=ds_tmp.interp_like(ds_new_grid)\n",
    "    \n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define months and years to get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990,\n",
       "       1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001,\n",
       "       2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012,\n",
       "       2013, 2014, 2015])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Months list\n",
    "mnums=['01','02','03','12']\n",
    "\n",
    "# Dates\n",
    "sdate='19800101'\n",
    "edate='20151231'\n",
    "\n",
    "# Years List\n",
    "yrs_list=np.arange(1980,2016)\n",
    "yrs_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define file path and names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "path='/shared/working/rean/era-interim/daily/data/'\n",
    "fname='ei.oper.an.pl.regn128cm.'\n",
    "\n",
    "# Output\n",
    "out_path='/project/predictability/kpegion/wxregimes/era-interim/'\n",
    "ofname='erai.z500_u250_pna_DJF.1980-2015.nc'\n",
    "outfile=out_path+ofname"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in the files for all months and years, and prepocess to subset data for Z500hPa and U250 in the PNA region & interpolate to coarser grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['1980-01-01', '1980-01-02', '1980-01-03', '1980-01-04',\n",
      "               '1980-01-05', '1980-01-06', '1980-01-07', '1980-01-08',\n",
      "               '1980-01-09', '1980-01-10',\n",
      "               ...\n",
      "               '2015-12-22', '2015-12-23', '2015-12-24', '2015-12-25',\n",
      "               '2015-12-26', '2015-12-27', '2015-12-28', '2015-12-29',\n",
      "               '2015-12-30', '2015-12-31'],\n",
      "              dtype='datetime64[ns]', length=13149, freq='D')\n",
      "DatetimeIndex(['1980-01-01', '1980-01-02', '1980-01-03', '1980-01-04',\n",
      "               '1980-01-05', '1980-01-06', '1980-01-07', '1980-01-08',\n",
      "               '1980-01-09', '1980-01-10',\n",
      "               ...\n",
      "               '2015-01-22', '2015-01-23', '2015-01-24', '2015-01-25',\n",
      "               '2015-01-26', '2015-01-27', '2015-01-28', '2015-01-29',\n",
      "               '2015-01-30', '2015-01-31'],\n",
      "              dtype='datetime64[ns]', length=1116, freq=None)\n",
      "DatetimeIndex(['1980-01-01', '1980-01-02', '1980-01-03', '1980-01-04',\n",
      "               '1980-01-05', '1980-01-06', '1980-01-07', '1980-01-08',\n",
      "               '1980-01-09', '1980-01-10',\n",
      "               ...\n",
      "               '2015-12-22', '2015-12-23', '2015-12-24', '2015-12-25',\n",
      "               '2015-12-26', '2015-12-27', '2015-12-28', '2015-12-29',\n",
      "               '2015-12-30', '2015-12-31'],\n",
      "              dtype='datetime64[ns]', length=13149, freq='D')\n",
      "DatetimeIndex(['1980-02-01', '1980-02-02', '1980-02-03', '1980-02-04',\n",
      "               '1980-02-05', '1980-02-06', '1980-02-07', '1980-02-08',\n",
      "               '1980-02-09', '1980-02-10',\n",
      "               ...\n",
      "               '2015-02-19', '2015-02-20', '2015-02-21', '2015-02-22',\n",
      "               '2015-02-23', '2015-02-24', '2015-02-25', '2015-02-26',\n",
      "               '2015-02-27', '2015-02-28'],\n",
      "              dtype='datetime64[ns]', length=1017, freq=None)\n",
      "DatetimeIndex(['1980-01-01', '1980-01-02', '1980-01-03', '1980-01-04',\n",
      "               '1980-01-05', '1980-01-06', '1980-01-07', '1980-01-08',\n",
      "               '1980-01-09', '1980-01-10',\n",
      "               ...\n",
      "               '2015-12-22', '2015-12-23', '2015-12-24', '2015-12-25',\n",
      "               '2015-12-26', '2015-12-27', '2015-12-28', '2015-12-29',\n",
      "               '2015-12-30', '2015-12-31'],\n",
      "              dtype='datetime64[ns]', length=13149, freq='D')\n",
      "DatetimeIndex(['1980-03-01', '1980-03-02', '1980-03-03', '1980-03-04',\n",
      "               '1980-03-05', '1980-03-06', '1980-03-07', '1980-03-08',\n",
      "               '1980-03-09', '1980-03-10',\n",
      "               ...\n",
      "               '2015-03-22', '2015-03-23', '2015-03-24', '2015-03-25',\n",
      "               '2015-03-26', '2015-03-27', '2015-03-28', '2015-03-29',\n",
      "               '2015-03-30', '2015-03-31'],\n",
      "              dtype='datetime64[ns]', length=1116, freq=None)\n",
      "DatetimeIndex(['1980-01-01', '1980-01-02', '1980-01-03', '1980-01-04',\n",
      "               '1980-01-05', '1980-01-06', '1980-01-07', '1980-01-08',\n",
      "               '1980-01-09', '1980-01-10',\n",
      "               ...\n",
      "               '2015-12-22', '2015-12-23', '2015-12-24', '2015-12-25',\n",
      "               '2015-12-26', '2015-12-27', '2015-12-28', '2015-12-29',\n",
      "               '2015-12-30', '2015-12-31'],\n",
      "              dtype='datetime64[ns]', length=13149, freq='D')\n",
      "DatetimeIndex(['1980-12-01', '1980-12-02', '1980-12-03', '1980-12-04',\n",
      "               '1980-12-05', '1980-12-06', '1980-12-07', '1980-12-08',\n",
      "               '1980-12-09', '1980-12-10',\n",
      "               ...\n",
      "               '2015-12-22', '2015-12-23', '2015-12-24', '2015-12-25',\n",
      "               '2015-12-26', '2015-12-27', '2015-12-28', '2015-12-29',\n",
      "               '2015-12-30', '2015-12-31'],\n",
      "              dtype='datetime64[ns]', length=1116, freq=None)\n"
     ]
    }
   ],
   "source": [
    "# Create empty list to append data for each month\n",
    "ds_Z_months=[]\n",
    "ds_U_months=[]\n",
    "\n",
    "# Loop over months, get list of files and read in data for each month\n",
    "for mnum in mnums:\n",
    "        \n",
    "    \n",
    "    # Get all the filenames for this month for all years\n",
    "    fnamesZ = [f'{path}{year}/{fname}{year}{mnum}*' for year in yrs_list]       \n",
    "   \n",
    "    # Create list of all filenames for this month, and all years\n",
    "    filesZ=[]\n",
    "    for files in fnamesZ:\n",
    "        f2=glob.glob(files)\n",
    "        for f in f2:\n",
    "            filesZ.append(f)\n",
    "    \n",
    "    filesZ=sorted(filesZ)\n",
    "    #print(filesZ)\n",
    "    \n",
    "    # Read Geopotential Height (Z) data           \n",
    "    ds_Z=xr.open_mfdataset(filesZ,engine='cfgrib',\n",
    "                           combine='nested',concat_dim=['time'],\n",
    "                           backend_kwargs={'indexpath':'',\n",
    "                                           'filter_by_keys':{'name': 'Geopotential'}},\n",
    "                           preprocess=preprocZ)\n",
    " \n",
    "    # Read zonal wind (U) data\n",
    "    ds_U=xr.open_mfdataset(filesZ,engine='cfgrib',\n",
    "                           combine='nested',concat_dim=['time'],\n",
    "                           backend_kwargs={'indexpath':'',\n",
    "                                           'filter_by_keys':{'name': 'U component of wind'}},\n",
    "                           preprocess=preprocU) \n",
    "\n",
    "    \n",
    "    # Create dates for time assign to time dimension\n",
    "    dates_all=pd.date_range(start=sdate,end=edate,freq='D')\n",
    "    print(dates_all)\n",
    "    djf_dates=dates_all[(dates_all.month==int(mnum))]\n",
    "    print(djf_dates)\n",
    "    ds_Z['time']=djf_dates\n",
    "    ds_U['time']=djf_dates\n",
    "        \n",
    "    # Append the latest month to the list\n",
    "    ds_Z_months.append(ds_Z)\n",
    "    ds_U_months.append(ds_U)\n",
    "        \n",
    "# Combine the months into the init dimension\n",
    "ds_Z_months = xr.combine_nested(ds_Z_months, concat_dim='time')\n",
    "ds_U_months = xr.combine_nested(ds_U_months, concat_dim='time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine z500 and u250 together into single `xr.Dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_ZU=xr.merge([ds_Z_months,ds_U_months])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write to netcdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_ZU.to_netcdf(outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (aoes)",
   "language": "python",
   "name": "aoes"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
